# ğŸ¤– ISRO IRoC Rover Challenge 2024

![ROS2](https://img.shields.io/badge/ROS2-Robot%20Operating%20System-blue) ![YOLOv8](https://img.shields.io/badge/YOLOv8-Computer%20Vision-red) ![Jetson%20Nano](https://img.shields.io/badge/Jetson%20Nano-Edge%20AI-green) ![Python](https://img.shields.io/badge/Python-3.8+-yellow)

This repository presents the **Rover Prototype** developed for the **ISRO IRoC Rover Challenge (Dec 2023 â€“ May 2024)**. The rover was designed for autonomous exploration, object detection, and environment interaction using **ROS2**, **YOLOv8**, and **Python**.

---

## ğŸš€ Project Overview

The project aimed to engineer a **fully autonomous rover** capable of object detection, depth estimation, and dynamic manipulation using a robotic arm. The rover integrates deep learning models, custom path planning algorithms, and real-time control through ROS2.


## ğŸ“¹ Demonstration


https://github.com/user-attachments/assets/3d454811-f563-46d1-88e9-124d441acad5


---

### ğŸ”¹ Key Achievements

* ğŸ›°ï¸ Designed and built a rover prototype for **ISRO IRoC 2024**
* ğŸ” Fine-tuned **YOLOv8** for custom object detection
* ğŸ“ Implemented **Expandable YOLO** for depth estimation up to **3 meters**
* ğŸ¦¾ Designed a **computer vision-aided robotic arm** for responsive manipulation
* âš™ï¸ Modified **Theta*** path planning algorithm achieving **<300ms inference time**

---

## ğŸ§  Technology Stack

| Component                | Technology Used               |
| ------------------------ | ----------------------------- |
| **Operating System**     | Raspbian OS                   |
| **Framework**            | ROS2 (Robot Operating System) |
| **Programming Language** | Python                        |
| **Computer Vision**      | OpenCV, YOLOv8, PyTorch       |
| **Hardware Design**      | SolidWorks                    |
| **Interface**            | Gradio, CSS                   |

---

## âš™ï¸ Installation & Setup

### Prerequisites

* Python 3.8+
* ROS2 Foxy / Humble
* OpenCV and PyTorch installed
* Compatible hardware (Raspberry Pi or Jetson Nano)
  
---

## ğŸ§© Core Functionalities

* **Autonomous Navigation:** Path planning using a modified Theta* algorithm
* **Object Detection:** Fine-tuned YOLOv8 for high accuracy on custom datasets
* **Depth Estimation:** Expandable YOLO detects object depth up to 3m
* **Dynamic Manipulation:** Robotic arm reacts to detected objects in real-time

---

## ğŸš§ Future Enhancements

* Integration with **GPS and LiDAR** for outdoor navigation
* Implementation of **multi-object tracking**
* Real-time telemetry dashboard using **Gradio**

---
